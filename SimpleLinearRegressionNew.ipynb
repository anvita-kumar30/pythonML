{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqm-nnIO63KX",
        "outputId": "85a84ca6-69cf-4c70-f4ad-cc1dde52789c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: m = 0.14768165161048522, c = 0.13640008200203796\n",
            "Iteration 2: m = 0.28915102809136106, c = 0.26729467961453357\n",
            "Iteration 3: m = 0.4246650831853794, c = 0.39291073821081807\n",
            "Iteration 4: m = 0.5544701570026656, c = 0.5134658316686849\n",
            "Iteration 5: m = 0.6788024143740226, c = 0.6291685494133273\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.07      1.00      0.13         7\n",
            "           1       1.00      0.00      0.00        93\n",
            "\n",
            "    accuracy                           0.07       100\n",
            "   macro avg       0.54      0.50      0.07       100\n",
            "weighted avg       0.93      0.07      0.01       100\n",
            "\n",
            "Accuracy: 0.07\n",
            "Precision: 1.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n",
            "Specificity: 1.0\n",
            "ROC-AUC Score: 0.5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
        "\n",
        "class SimpleLinearRegression:\n",
        "    def __init__(self, learning_rate=0.01, n_iters=5):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.m = 0\n",
        "        self.c = 0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n = len(y)\n",
        "        for i in range(self.n_iters):\n",
        "            # Predicted values\n",
        "            y_pred = self.m * X + self.c\n",
        "\n",
        "            # Compute gradients for m and c\n",
        "            dm = -(2/n) * np.sum(X * (y - y_pred))\n",
        "            dc = -(2/n) * np.sum(y - y_pred)\n",
        "\n",
        "            # Update m and c\n",
        "            self.m = self.m - self.learning_rate * dm\n",
        "            self.c = self.c - self.learning_rate * dc\n",
        "\n",
        "            # Print m and c values after each iteration\n",
        "            print(f\"Iteration {i+1}: m = {self.m}, c = {self.c}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.m * X + self.c\n",
        "\n",
        "# Generate some sample data for linear regression\n",
        "np.random.seed(42)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "# Convert to 1D for gradient descent\n",
        "X = X.flatten()\n",
        "y = y.flatten()\n",
        "\n",
        "# Initialize and run gradient descent\n",
        "regressor = SimpleLinearRegression(learning_rate=0.01, n_iters=5)\n",
        "regressor.fit(X, y)\n",
        "\n",
        "# Predictions for the dataset\n",
        "y_pred = regressor.predict(X)\n",
        "\n",
        "# Classification threshold: Turn regression outputs into binary classes (threshold = 4.5)\n",
        "y_binary_true = (y > 4.5).astype(int)\n",
        "y_binary_pred = (y_pred > 4.5).astype(int)\n",
        "\n",
        "# Print classification metrics using sklearn\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_binary_true, y_binary_pred, zero_division=1))  # zero_division=1 suppresses the warning\n",
        "\n",
        "# Calculate confusion matrix for specificity\n",
        "conf_matrix = confusion_matrix(y_binary_true, y_binary_pred)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_binary_true, y_binary_pred)}\")\n",
        "print(f\"Precision: {precision_score(y_binary_true, y_binary_pred, zero_division=1)}\")  # zero_division=1 here too\n",
        "print(f\"Recall: {recall_score(y_binary_true, y_binary_pred)}\")\n",
        "print(f\"F1 Score: {f1_score(y_binary_true, y_binary_pred, zero_division=1)}\")\n",
        "print(f\"Specificity: {specificity}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc_score(y_binary_true, y_binary_pred)}\")"
      ]
    }
  ]
}